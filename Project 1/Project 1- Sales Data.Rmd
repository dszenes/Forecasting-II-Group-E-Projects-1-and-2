
```{r}
load("TX_2.rdata")
```

```{r}
library(fpp3)

## Sales data

product_list <- unique(sales$item_id) 
length(product_list)

unique(sales$dept_id)


# 1437 products, 3 departments

unique(sales$store_id) # only one value, can remove variable
sales <- sales %>% select(-store_id)
prices <- prices %>% select(-store_id)

library(data.table) 

setDT(sales)[, .(count = uniqueN(item_id)), by = dept_id] # number of items per department

total_sales <- sales %>%
  select(day, sales) %>%
  group_by(day) %>%
  summarise(tot_sales = sum(sales)) %>%
  as_tsibble()

options(scipen = 999)

total_sales %>%
  mutate(Month = yearmonth(day)) %>%
  filter( Month > yearmonth("2011 Jan") & Month < yearmonth("2016 Apr") ) %>%
  as_tibble() %>%
  group_by(Month) %>%
  summarise(tot_sales = sum(tot_sales))  %>%
  tsibble() %>%
  autoplot()
```

```{r}
#Visualizing Total Sales over time to see main pattern of our data
total_sales %>% autoplot(tot_sales)
#AFC plot: not white noise here, coeff are pretty high/significant, way above confidence interval most of the time: seems to have a strong pattern/seasonality
total_sales %>% ACF(tot_sales) %>% autoplot()
#seasonal subseries plot: chart by month to see evolution of time series during the years for a particular month
x <- total_sales %>%
  mutate(Month = yearmonth(day)) %>%
  filter( Month > yearmonth("2011 Jan") & Month < yearmonth("2016 Apr") ) %>%
  as_tibble()
```

```{r}
total_sales %>% model(STL(tot_sales)) %>% components() %>% autoplot()
#STL decomposition of the total sales per day
#we've to change daily to monthly/quarter
```

```{r}
#sales data: from daily to monthly
data_new2 <- as.data.frame(sales)
data_new2$year_month <- floor_date(data_new2$day,"month")

data_aggr2 <- data_new2 %>%
  group_by(year_month) %>% 
  dplyr::summarize(tot_sales = sum(tot_sales)) %>% 
  as_tsibble()

monthly_sales_data <-
  data_aggr2 %>%
  mutate(year_month = yearmonth(year_month)) %>%
  as_tsibble(index = year_month)

monthly_sales_data %>% filter(year_month > yearmonth("2011 Jan")) %>% 
  model(STL(tot_sales ~ trend(window = 21))) %>%
  components() %>%
  autoplot()

monthly_sales_data %>% filter(year_month > yearmonth("2011 Jan")) %>% gg_subseries(tot_sales) + ylab("Total Sales") + xlab("Year")
```

```{r}
##hierarchical structure : product, department analysis
sales1 <- tsibble(sales, index = day, key = c(item_id, dept_id))
sales_hts <- sales1 %>%
    aggregate_key(item_id / dept_id, sales = sum(sales)) #takes a bit of time

#Problem with following code: Don't stop running, maybe because too much data
#Maybe should take sales of each product by month instead of by day
sales_hts %>%
    filter(is_aggregated(dept_id)) %>%
    autoplot(sales) + ylab("Sales") +
    facet_wrap(vars(item_id), scales =
                   "free_y"
               , ncol = 3) +
    theme(legend.position =
              "none")

## ARIMA  + linear regression (add dummy with snap benefits + special events)
fit <- monthly_sales_data %>% 
     model(arima = ARIMA(tot_sales))
report(fit)
fit %>% gg_tsresiduals() #to check if residuals are white noise
fit %>% forecast(h = 28) %>% autoplot(monthly_sales_data) #Forecast


#creation of snap benefits dummy variable
total_sales$snap <- ifelse(day(total_sales$day) == 1 | day(total_sales$day) == 3 | day(total_sales$day) == 5 | day(total_sales$day) == 6 | day(total_sales$day) == 7 | day(total_sales$day) == 9 | day(total_sales$day) == 11 |  day(total_sales$day) == 12 | day(total_sales$day) == 13 | day(total_sales$day) == 15, "TRUE", "FALSE") #or O and 1

#Linear model
fit_lm <- total_sales %>%
          model(reg = TSLM(tot_sales ~ trend() + season() + snap))
total_sales %>%
     autoplot(tot_sales, col = "gray") +
     geom_line(data = augment(fit_lm), aes(y = .fitted), col = "blue") #too compact, should make it wider so that can interpret it better, or maybe plot is not correct ?

```

```{r}
## Calendar data
?autoplot

unique(cal$type_1) 
# 4 types of events

cal %>%
  filter(name_1 != "") 

# 162 days with events

cal %>%
  mutate(event = name_1 != "") %>%
  mutate(month = strftime(cal$date, format = "%m")) %>%
  filter(event == TRUE)  %>%
  ggplot(aes(month)) +
  geom_histogram(stat="count")

# particularly many events in February and few in August
  

cal %>%
  filter(name_2 != "") 

# 5 days with 2 events, these might appear as outliers in the dataset
cal %>%
  mutate(day = strftime(cal$date, format = "%d")) %>%
  select( day, snap_TX)  %>%
  ggplot(aes(day, snap_TX)) +
  geom_point() 

#snap benefits are distributed in sequence : 1,3,5,6,7,9,11,12,13,15 every month throughout the data set

cal %>%
  mutate(day = strftime(cal$date, format = "%d")) %>%
  select( day, snap_CA)  %>%
  ggplot(aes(day, snap_CA)) +
  geom_point()
cal %>%
  mutate(day = strftime(cal$date, format = "%d")) %>%
  select( day, snap_WI)  %>%
  ggplot(aes(day, snap_WI)) +
  geom_point() 
#Those two are useless becasue the store is located in TX
cal <- cal %>% select(-snap_CA, -snap_WI, -wday)
```

```{r}
## Prices data

product_list_2 <- unique(prices$item_id)

# we only have sales data for foods products, but we have prices for other products 
prices %>%
  filter(item_id == product_list[1]  ) %>%
  ggplot(aes(wm_yr_wk, sell_price)) +
  geom_point()

 # we can see the evolution of the price of any product, we  need to transform the wm_yr_wk variable to get a continuous time variable



# Little overlooking on total sales time serie features

sales_features <- monthly_sales_data %>% features(tot_sales, feature_set(pkgs = "feasts"))
sales_features

?features

# we have only 1 row because only 1 time serie: total sales.
# results: quite high trend strength (0.76), relatively moderate seasonality strenght (0.48)....




# Hierarchical model building (trial)
# The hierarchy is the following: item_id (food) --> dept_id ( Department) --> store_id (store), Actually we only have one store: TX_2 for the hierarchical building should we keep it or not? (probably not, question to ask)

# TO merge price and sales dataset we should look at the key variable: item_id

# Modification on price dataset: we need only item_id on FOOD, so filter on that

prices_wra <- prices[369235:701214,] # Selecting only the rows linked with FOODS products.

merged_dataset <- merge(prices_wra,sales, by= "item_id")

# Error: cannot allocate vector of size 4.7 Gb






```
