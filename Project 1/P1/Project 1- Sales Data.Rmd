
```{r}
load("TX_2.rdata")
```

```{r}
library(fpp3)
library(data.table)

## Sales data
product_list <- unique(sales$item_id) 
length(product_list)
unique(sales$dept_id)
# 1437 products, 3 departments

unique(sales$store_id) # only one store

setDT(sales)[, .(count = uniqueN(item_id)), by = dept_id] # number of items per department

View(is.na(sales))
#no missing values in this data set
```

```{r}
options(scipen = 999)

total_sales <- sales %>%
  group_by(day) %>%
  summarise(tot_sales = sum(sales)) %>%
  as_tsibble() %>% filter_index("2014-01-01"~ "2016-04-25")

total_sales %>% autoplot()

#there are outliers in the data (26/12)
total_sales %>%
  mutate(Month = yearmonth(day)) %>%
  as_tibble() %>%
  group_by(Month) %>%
  summarise(tot_sales = sum(tot_sales))  %>%
  tsibble() %>%
  autoplot()
```

```{r}
#AFC plot: not white noise here, coeff are pretty high/significant, way above confidence interval most of the time: seems to have a strong pattern/seasonality
total_sales %>% ACF(tot_sales) %>% autoplot()
#seasonal subseries plot: chart by month to see evolution of time series during the years for a particular month
total_sales %>%
  mutate(Month = yearmonth(day)) %>%
  filter( Month > yearmonth("2011 Jan") & Month < yearmonth("2016 Apr") ) %>%
  as_tibble()
```

```{r}
total_sales %>% model(STL(tot_sales)) %>% components() %>% autoplot()
#STL decomposition of the total sales per day
#for this representation, we've to change daily to monthly/quarter (too noisy)

#sales data: from daily to monthly
data_new2 <- as.data.frame(sales)
data_new2$year_month <- floor_date(data_new2$day,"month")

data_aggr2 <- data_new2 %>%
  group_by(year_month) %>%
  summarize(tot_sales = sum(sales)) %>% 
  as_tsibble()

monthly_sales_data <-
  data_aggr2 %>%
  mutate(year_month = yearmonth(year_month)) %>%
  as_tsibble(index = year_month)

monthly_sales_data %>%
  filter(year_month > yearmonth("2011 Jan")) %>% 
  model(STL(tot_sales ~ trend(window = 21))) %>%
  components() %>%
  autoplot()

monthly_sales_data %>%
  filter(year_month > yearmonth("2013 Dec") & year_month < yearmonth("2016 Apr")) %>%
  gg_subseries(tot_sales) + ylab("Total Sales") + xlab("Year")
#as there is a lot of data
#is it useful to have all the time information?
#we can see that the trend stop decreasing in 2014: we can filter from this date
```

```{r}
#Visualizing Total Sales over time to see main pattern of our data
total_sales %>% autoplot(tot_sales)
#we can see some outliers
total_sales %>% filter(tot_sales < 1000)
#day        tot_sales
#2011-12-26	0			
#2012-12-26	0
#2013-12-26	11
#2014-03-27	782			can be explain by St Patrick Day (cal row = 1144)
#2014-12-26	7       outliers 1
#2015-03-25	93      outliers 2
#2015-12-26	0       outliers 3

total_sales %>%
  mutate(Month = yearmonth(day)) %>%
  filter(Month >= yearmonth("2014 Jan")) %>% autoplot()

total_sales %>% filter(tot_sales > 5000) #outliers because of NBAFinalsEnd (row 1600 in the cal data)
#day        tot_sales
#2015-06-16	5251	
```

```{r}
sales_ts <- sales %>% as_tsibble(index = day, key = c(store_id, dept_id, item_id)) %>% filter_index("2014-01-01"~.)
#without product in the hierarchical

##hierarchical structure : hierarchy : deparment -> store
# there are 1437 products. I propose to disregard the lowest hierarchy (the products) because too much products ? Maybe concentrate ourselves on the top 5 selling products?
```

```{r}
#keep outliers in memory
outliers <- sales_ts %>%
  filter_index("2014-12-26", "2015-03-25" ,"2015-12-26", "2014-03-27")
```

```{r}
sales_ts_miss <- sales_ts %>% 
  anti_join(outliers) %>% #remove outliers
  fill_gaps() #replace them by missing values

sales_ts_fill <- sales_ts_miss %>% # Fit TSLM model to the data containing missing values
  model(naive = TSLM(sales ~ trend())) %>% # Estimate tot_sales for all periods
  interpolate(sales_ts_miss)
```

```{r}
#removing outliers in total_sales object
total_ts_sales <- sales_ts_fill %>%
  summarise(tot_sales = sum(sales)) %>%
  as_tsibble() %>% filter_index("2014-01-01"~ "2016-04-25")
```

```{r}
#departement sales vizualizations
options(scipen = 999)

total_dep_sales <- sales_ts_fill %>%
  group_by(dept_id) %>%
  summarise(sales = sum(sales))

dep1tot_sales <- total_dep_sales %>%
  filter(dept_id == "FOODS_1") %>%
  as_tsibble()

dep2tot_sales <- total_dep_sales %>%
  filter(dept_id == "FOODS_2") %>%
  as_tsibble()

dep3tot_sales <- total_dep_sales %>%
  filter(dept_id == "FOODS_3") %>%
  as_tsibble()

dep1tot_sales %>% filter_index("2014-01-01"~.) %>% autoplot(sales)
dep2tot_sales %>% filter_index("2014-01-01"~.) %>% autoplot(sales)
dep3tot_sales %>% filter_index("2014-01-01"~.) %>% autoplot(sales)
```

```{r}
dep1tot_sales %>%
  filter_index("2014-01-01"~.) %>%
  filter(sales < 100)

dep2tot_sales %>%
  filter_index("2014-01-01"~.) %>%
  filter(sales < 200)

dep3tot_sales %>%
  filter_index("2014-01-01"~.) %>%
  filter(sales < 1000)

# we can see a sale decrease @ 2014-03-27 in the 3 department
# no explanation in the cal data set
#take this data as outlier
```

```{r}
## Calendar data
unique(cal$type_1) 
# 4 types of events

cal %>%
  filter(name_1 != "") 

# 162 days with events

cal %>%
  mutate(event = name_1 != "") %>%
  mutate(month = strftime(cal$date, format = "%m")) %>%
  filter(event == TRUE)  %>%
  ggplot(aes(month)) +
  geom_histogram(stat="count")

# particularly many events in February and few in August
  

cal %>%
  filter(name_2 != "") 

# 5 days with 2 events, these might appear as outliers in the dataset
cal %>%
  mutate(day = strftime(cal$date, format = "%d")) %>%
  select( day, snap_TX)  %>%
  ggplot(aes(day, snap_TX)) +
  geom_point() 

#snap benefits are distributed in sequence : 1,3,5,6,7,9,11,12,13,15 every month throughout the data set
cal <- cal %>%
  select(-snap_CA, -snap_WI, -wday)
```

```{r}
#cal dataset manipulation: from tibble to tsibble
cal <- cal %>% 
  mutate(date = date(
    as.Date(date,
      format = "%Y-%m-%d"))) %>%
  as_tsibble()#chr to date


cal2014 <- cal %>%
  filter_index("2014-01-01" ~"2016-05-23") %>%
  select(date, name_1, name_2, snap_TX, wm_yr_wk)
```

```{r}
library(stringr)
prices <- prices %>%
  filter_all(any_vars(str_detect(., pattern = "FOOD")))

prices %>%
  ggplot(aes(wm_yr_wk, sell_price)) +
  geom_point()

#we can see the evolution of the price of any product, we  need to transform the wm_yr_wk variable to get a continuous time variable
```

```{r}
cal_price <- full_join(as_tibble(cal), as_tibble(prices), by = "wm_yr_wk") %>% select(-wm_yr_wk)
```

```{r}
#creation of snap benefits dummy variable
total_ts_sales$snap <-
  ifelse(
    day(total_sales$day) == 1 |
      day(total_sales$day) == 3 |
      day(total_sales$day) == 5 |
      day(total_sales$day) == 6 |
      day(total_sales$day) == 7 |
      day(total_sales$day) == 9 |
      day(total_sales$day) == 11 |
      day(total_sales$day) == 12 |
      day(total_sales$day) == 13 |
      day(total_sales$day) == 15,
    "TRUE",
    "FALSE"
  )
#or O and 1
```

```{r}
ETS <- total_ts_sales %>% model(ETS(tot_sales))
```

```{r}
#merging the sales & cal data set
total_ts_sales <- total_ts_sales %>% rename(date = day)
df <- full_join(as_tibble(cal2014), as_tibble(total_ts_sales), by = "date")

df <- df %>% as_tsibble(index = date)
```

```{r}
sales_ts_fill <- sales_ts_fill %>% rename(date = day)
df2 <- full_join(as_tibble(cal2014), as_tibble(sales_ts_fill), by = "date")
df2 <- df2 %>% as_tsibble(index = date, key = c(store_id, dept_id, item_id))

```

```{r}
#creation of events dummy variable
df <-
  fastDummies::dummy_cols(df, select_columns = c("name_1", "name_2")) %>%
  select(-name_1, -name_2, -snap_TX)
df <- df %>% as_tsibble()
```

```{r}
#ETS model
ETS <- total_ts_sales %>% model(ETS(tot_sales))
ETS %>%
  forecast(h=28) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))
```

```{r}
#MEAN + NAIVE + SNAIVE

sales_fit <- total_ts_sales %>%
  model(
    Mean = MEAN(tot_sales),
    `Naïve` = NAIVE(tot_sales),
    `Seasonal naïve` = SNAIVE(tot_sales)
  )

sales_fit %>%
  forecast(h=28) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))
```

```{r}
#Linear model
fit_lm <- df %>% 
          model(TSLM(tot_sales ~ trend() + season() + snap))

future_souvenirs <- new_data(total_ts_sales, n = 28) %>%
  mutate(snap = 
    ifelse(
      day(df[847:874,]$date) == 1 |
        day(df[847:874,]$date) == 3 |
        day(df[847:874,]$date) == 5 |
        day(df[847:874,]$date) == 6 |
        day(df[847:874,]$date) == 7 |
        day(df[847:874,]$date) == 9 |
        day(df[847:874,]$date) == 11 |
        day(df[847:874,]$date) == 12 |
        day(df[847:874,]$date) == 13 |
        day(df[847:874,]$date) == 15,
      "TRUE",
      "FALSE"
    )
  )

fit_lm %>%
  forecast(new_data = future_souvenirs) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))

```

```{r}
#event dummy 1st try
fit_all_lm <- df %>%
  model(TSLM(
      tot_sales ~ trend() +
        season() + snap +
        `name_1_Mother's day` +
        name_1_OrthodoxEaster + 
        `name_1_Pesach End` + `name_1_Cinco De Mayo`
  ))


future_souvenirs <- new_data(total_ts_sales, n = 28) %>%
  mutate(`name_1_Cinco De Mayo` = ifelse(df[847:874,]$`name_1_Cinco De Mayo` == 1, "TRUE", "FALSE")) %>%
  mutate(`name_1_Mother's day` = ifelse(df[847:874,]$`name_1_Mother's day` == 1, "TRUE", "FALSE")) %>%
  mutate(name_1_OrthodoxEaster = ifelse(df[847:874,]$name_1_OrthodoxEaster == 1, "TRUE", "FALSE")) %>%
  mutate(`name_1_Pesach End` = ifelse(df[847:874,]$`name_1_Pesach End` == 1, "TRUE", "FALSE")) %>%
  mutate(snap = 
           ifelse(
             day(df[847:874,]$date) == 1 |
               day(df[847:874,]$date) == 3 |
               day(df[847:874,]$date) == 5 |
               day(df[847:874,]$date) == 6 |
               day(df[847:874,]$date) == 7 |
               day(df[847:874,]$date) == 9 |
               day(df[847:874,]$date) == 11 |
               day(df[847:874,]$date) == 12 |
               day(df[847:874,]$date) == 13 |
               day(df[847:874,]$date) == 15,
             "TRUE",
             "FALSE"
           )
  )

fit_all_lm %>%
  forecast(new_data = future_souvenirs) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))
```


```{r}
#ARIMA model -> just with snap dummy
fit_ARIMA1 <- df %>% 
          model(ARIMA(tot_sales ~ trend() + season() + snap))
fit_ARIMA2 <- df %>% 
          model(ARIMA(tot_sales ~ snap))

fit_ARIMA1 %>%
  forecast(new_data = future_souvenirs) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))
fit_ARIMA2 %>%
  forecast(new_data = future_souvenirs) %>%
  autoplot(total_ts_sales %>% filter_index("2016"~.))
```


```{r}
#hierarchy : department -> store
sales_aggr <- df2 %>%
  filter_index(.~"2016-04-25") %>% #remove the future cal date
  aggregate_key(store_id/ dept_id / item_id, sales = sum(sales))

sales_aggr %>%
  filter(is_aggregated(store_id)) %>%
  autoplot(sales) +
  ylab("Sales") +
  theme(legend.position =
          "none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

sales_aggr %>%
  filter(!is_aggregated(store_id),!is_aggregated(dept_id), is_aggregated(item_id)) %>%
  autoplot(sales) +
  ylab("Sales") +
  theme(legend.position =
          "none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

sales_aggr %>%
  filter(!is_aggregated(store_id),!is_aggregated(dept_id), !is_aggregated(item_id)) %>%
  autoplot(sales) +
  ylab("Sales") +
  theme(legend.position =
          "none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r}
fit_aggr <- sales_aggr %>%
  filter(is_aggregated(store_id)) %>% 
  model(base = ARIMA(sales)) %>%
  reconcile(
    bu = bottom_up(base)
  )


fc <- fit_aggr %>% forecast(h = 28)

fc %>%
  filter(is_aggregated(store_id)) %>%
  autoplot(
    sales_aggr
  )
#the model do a poor job for dep 1 and 2
#how can we fix this issue?
```

```{r}
# Little overlooking on total sales time serie features
sales_features <- monthly_sales_data %>% features(tot_sales, feature_set(pkgs = "feasts"))
sales_features
?features
# we have only 1 row because only 1 time serie: total sales.
# results: quite high trend strength (0.76), relatively moderate seasonality strenght (0.48)....
# Hierarchical model building (trial)
# The hierarchy is the following: item_id (food) --> dept_id ( Department) --> store_id (store), Actually we only have one store: TX_2 for the hierarchical building should we keep it or not? (probably not, question to ask)
# TO merge price and sales dataset we should look at the key variable: item_id
# Modification on price dataset: we need only item_id on FOOD, so filter on that
prices_wra <- prices[369235:701214,] # Selecting only the rows linked with FOODS products.
merged_dataset <- merge(prices_wra,sales, by= "item_id")
# Error: cannot allocate vector of size 4.7 Gb
```
